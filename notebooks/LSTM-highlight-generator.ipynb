{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Classification with ResNet and LSTM\n",
    "\n",
    "This notebook demonstrates a workflow for video classification using a combination of a ResNet-34 model for feature extraction and an LSTM (Long Short-Term Memory) for temporal modeling.\n",
    "\n",
    "## Overview\n",
    "\n",
    "1. **Environment Setup**\n",
    "2. **Model Architecture**\n",
    "3. **Dataset Preparation**\n",
    "4. **Training Pipeline**\n",
    "5. **Validation and Evaluation**\n",
    "6. **Saving the Final Model**\n",
    "\n",
    "## Output\n",
    "- The notebook outputs the trained model, saved checkpoints, and validation accuracy. The final model is saved as `resnet_lstm_highlight_model.pth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-13T16:10:10.197688Z",
     "iopub.status.busy": "2025-04-13T16:10:10.197051Z",
     "iopub.status.idle": "2025-04-13T23:19:34.406029Z",
     "shell.execute_reply": "2025-04-13T23:19:34.405296Z",
     "shell.execute_reply.started": "2025-04-13T16:10:10.197662Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: Tesla T4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
      "100%|██████████| 83.3M/83.3M [00:00<00:00, 186MB/s] \n",
      "/tmp/ipykernel_31/441316775.py:195: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=device.type == \"cuda\")\n",
      "Epoch 1/20:   0%|          | 0/562 [00:00<?, ?it/s]/tmp/ipykernel_31/441316775.py:207: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=device.type == \"cuda\"):\n",
      "Epoch 1/20: 100%|██████████| 562/562 [21:59<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train loss: 2.5090\n",
      "✔ Saved checkpoint → checkpoints/checkpoint_epoch_01.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 562/562 [21:18<00:00,  2.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | train loss: 2.2383\n",
      "✔ Saved checkpoint → checkpoints/checkpoint_epoch_02.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 562/562 [21:01<00:00,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | train loss: 2.0851\n",
      "✔ Saved checkpoint → checkpoints/checkpoint_epoch_03.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 562/562 [21:03<00:00,  2.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | train loss: 2.0570\n",
      "✔ Saved checkpoint → checkpoints/checkpoint_epoch_04.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 562/562 [20:58<00:00,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | train loss: 1.9392\n",
      "✔ Saved checkpoint → checkpoints/checkpoint_epoch_05.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 562/562 [20:55<00:00,  2.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | train loss: 1.9263\n",
      "✔ Saved checkpoint → checkpoints/checkpoint_epoch_06.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 562/562 [21:03<00:00,  2.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | train loss: 1.8315\n",
      "✔ Saved checkpoint → checkpoints/checkpoint_epoch_07.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 562/562 [21:04<00:00,  2.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | train loss: 1.7468\n",
      "✔ Saved checkpoint → checkpoints/checkpoint_epoch_08.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 562/562 [21:17<00:00,  2.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | train loss: 1.6805\n",
      "✔ Saved checkpoint → checkpoints/checkpoint_epoch_09.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 562/562 [21:08<00:00,  2.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | train loss: 1.6074\n",
      "✔ Saved checkpoint → checkpoints/checkpoint_epoch_10.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 562/562 [20:59<00:00,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | train loss: 1.5755\n",
      "✔ Saved checkpoint → checkpoints/checkpoint_epoch_11.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 562/562 [21:04<00:00,  2.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | train loss: 1.5000\n",
      "✔ Saved checkpoint → checkpoints/checkpoint_epoch_12.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████| 562/562 [21:08<00:00,  2.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | train loss: 1.4526\n",
      "✔ Saved checkpoint → checkpoints/checkpoint_epoch_13.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████| 562/562 [21:22<00:00,  2.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | train loss: 1.4135\n",
      "✔ Saved checkpoint → checkpoints/checkpoint_epoch_14.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████| 562/562 [21:07<00:00,  2.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | train loss: 1.3621\n",
      "✔ Saved checkpoint → checkpoints/checkpoint_epoch_15.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████| 562/562 [21:17<00:00,  2.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | train loss: 1.2911\n",
      "✔ Saved checkpoint → checkpoints/checkpoint_epoch_16.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|██████████| 562/562 [21:16<00:00,  2.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | train loss: 1.2369\n",
      "✔ Saved checkpoint → checkpoints/checkpoint_epoch_17.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|██████████| 562/562 [21:04<00:00,  2.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | train loss: 1.1705\n",
      "✔ Saved checkpoint → checkpoints/checkpoint_epoch_18.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|██████████| 562/562 [21:09<00:00,  2.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | train loss: 1.1798\n",
      "✔ Saved checkpoint → checkpoints/checkpoint_epoch_19.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████| 562/562 [21:19<00:00,  2.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | train loss: 1.1702\n",
      "✔ Saved checkpoint → checkpoints/checkpoint_epoch_20.pth\n",
      "\n",
      "Training complete – final model saved as 'resnet_lstm_highlight_model.pth'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31/441316775.py:253: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=device.type == \"cuda\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | val acc : 0.5638\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# ResNet-34 feature extractor\n",
    "class ResNetFeatureExtractor(nn.Module):\n",
    "    def __init__(self, fine_tune: bool = False):\n",
    "        super().__init__()\n",
    "        backbone = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)\n",
    "        self.backbone = nn.Sequential(*list(backbone.children())[:-1])  # strip FC\n",
    "        self.fine_tune = fine_tune\n",
    "        if not fine_tune:\n",
    "            for p in self.backbone.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "    def forward(self, x):  # (N, 3, 224, 224)\n",
    "        if self.fine_tune:\n",
    "            feats = self.backbone(x)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                feats = self.backbone(x)\n",
    "        return feats.view(x.size(0), -1)  # (N, 512)\n",
    "\n",
    "# ResNet-34 + LSTM classifier\n",
    "class LSTMWithResNet(nn.Module):\n",
    "    def __init__(self, feature_size: int, hidden_size: int, output_size: int,\n",
    "                 num_layers: int = 2, dropout: float = 0.3, fine_tune_cnn: bool = False):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = ResNetFeatureExtractor(fine_tune=fine_tune_cnn) # Create ResNet feature extractor\n",
    "        self.lstm = nn.LSTM(feature_size,\n",
    "                            hidden_size,\n",
    "                            num_layers=num_layers,\n",
    "                            batch_first=True,\n",
    "                            dropout=dropout if num_layers > 1 else 0.0) # Add LSTM layer\n",
    "        # Create a sequential classifier with two linear layers and ReLU activation\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size * 2, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # (B, T, C, H, W)\n",
    "        b, t, c, h, w = x.size()\n",
    "        x = x.view(-1, c, h, w)                      # (B*T, C, H, W)\n",
    "        feats = self.feature_extractor(x)            # (B*T, 512)\n",
    "        feats = feats.view(b, t, -1)                 # (B, T, 512)\n",
    "        lstm_out, _ = self.lstm(feats)               # (B, T, H)\n",
    "        logits = self.classifier(lstm_out[:, -1, :]) # last step\n",
    "        return logits\n",
    "\n",
    "# Video dataset class\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 video_paths: List[str],\n",
    "                 labels: List[str],\n",
    "                 label_to_index: dict,\n",
    "                 max_frames: int = 64,\n",
    "                 transform=None):\n",
    "        self.video_paths = video_paths # list of video file paths\n",
    "        self.labels = labels          # list of labels\n",
    "        self.label_to_index = label_to_index # mapping from labels to indices\n",
    "        self.max_frames = max_frames  # maximum number of frames to sample\n",
    "        self.transform = transform   # optional transform to apply to each frame\n",
    "\n",
    "    # Get length of dataset\n",
    "    def __len__(self):\n",
    "        return len(self.video_paths)\n",
    "\n",
    "    # Sample frames from the video\n",
    "    def _sample_frames(self, frames: List[np.ndarray]) -> List[np.ndarray]:\n",
    "        if len(frames) <= self.max_frames:\n",
    "            return frames\n",
    "        # uniform sampling\n",
    "        idxs = np.linspace(0, len(frames) - 1, self.max_frames, dtype=int)\n",
    "        return [frames[i] for i in idxs]\n",
    "\n",
    "    # Get item from dataset\n",
    "    def __getitem__(self, idx):\n",
    "        video_path = self.video_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        frames = []\n",
    "        cap = cv2.VideoCapture(video_path) # Open video file\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read() # Read frame\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = cv2.resize(frame, (224, 224))\n",
    "            frame = frame[:, :, ::-1]  # BGR→RGB\n",
    "            frame = frame / 255.0 # Normalize\n",
    "            if self.transform:\n",
    "                frame = self.transform(frame)\n",
    "            frames.append(frame)\n",
    "        cap.release()\n",
    "\n",
    "        if not frames:\n",
    "            raise RuntimeError(f\"Could not read frames from {video_path}\")\n",
    "\n",
    "        frames = self._sample_frames(frames)\n",
    "        frames = np.stack(frames)                      # (T, H, W, C)\n",
    "        frames_tensor = torch.tensor(frames).permute(0, 3, 1, 2).float()\n",
    "        label_idx = self.label_to_index[label] # convert label to index\n",
    "        return frames_tensor, label_idx\n",
    "\n",
    "# Load video data\n",
    "def load_data(root_directory):\n",
    "    video_paths, labels = [], []\n",
    "    for folder_name in os.listdir(root_directory):\n",
    "        folder_path = os.path.join(root_directory, folder_name) # Get path to folder\n",
    "        if os.path.isdir(folder_path):\n",
    "            for fname in os.listdir(folder_path): # Get all files in folder\n",
    "                if fname.lower().endswith((\".mp4\", \".avi\", \".mov\")): # Check if file is a video\n",
    "                    video_paths.append(os.path.join(folder_path, fname)) # Add video path to list\n",
    "                    labels.append(folder_name) # Add label to list\n",
    "    return video_paths, labels\n",
    "\n",
    "\n",
    "root_directory = r\"\"  # Path to the dataset directory\n",
    "video_paths, labels = load_data(root_directory) # Load video data\n",
    "\n",
    "unique_labels = sorted(set(labels)) # Get unique labels\n",
    "label_to_index = {lbl: i for i, lbl in enumerate(unique_labels)}\n",
    "index_to_label = {i: lbl for lbl, i in label_to_index.items()}\n",
    "\n",
    "# Split data into training and validation sets\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "    video_paths, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "# Hyperparameters\n",
    "feature_size = 512\n",
    "hidden_size = 512\n",
    "output_size = len(unique_labels) # number of unique labels\n",
    "num_layers = 2\n",
    "num_epochs = 20\n",
    "batch_size = 2  # reduce if still OOM\n",
    "learning_rate = 1e-4\n",
    "checkpoint_dir = \"checkpoints\" # directory to save checkpoints\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = VideoDataset(train_paths, train_labels, label_to_index)\n",
    "val_dataset = VideoDataset(val_paths,   val_labels,   label_to_index)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,  pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "# Create model, loss function, optimizer\n",
    "model = LSTMWithResNet(feature_size, hidden_size, output_size, num_layers).to(device)\n",
    "criterion = nn.CrossEntropyLoss() # Cross entropy loss\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate) # Adam optimizer\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=device.type == \"cuda\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for vids, lbls in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        vids, lbls = vids.to(device, non_blocking=True), lbls.to(device, non_blocking=True)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(enabled=device.type == \"cuda\"):\n",
    "            outputs = model(vids)\n",
    "            loss = criterion(outputs, lbls)\n",
    "        scaler.scale(loss).backward() # Backpropagation\n",
    "        scaler.step(optimizer) # Update weights\n",
    "        scaler.update() # Update scaler\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader) # Average loss\n",
    "    print(f\"Epoch {epoch+1:02d} | train loss: {avg_loss:.4f}\")\n",
    "\n",
    "    ckpt_path = os.path.join(checkpoint_dir, f\"checkpoint_epoch_{epoch+1:02d}.pth\")\n",
    "    torch.save({\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"train_loss\": avg_loss,\n",
    "        # \"val_acc\": val_acc,\n",
    "        \"timestamp\": datetime.utcnow().isoformat()\n",
    "    }, ckpt_path) # Save checkpoint\n",
    "    print(f\"✔ Saved checkpoint → {ckpt_path}\\n\")\n",
    "\n",
    "torch.save(model.state_dict(), \"resnet_lstm_highlight_model.pth\") # Save final model\n",
    "print(\"Training complete – final model saved as 'resnet_lstm_highlight_model.pth'.\")\n",
    "\n",
    "\n",
    "model.eval() # Set model to evaluation mode\n",
    "correct = total = 0\n",
    "with torch.no_grad():\n",
    "    for vids, lbls in val_loader:\n",
    "        vids, lbls = vids.to(device, non_blocking=True), lbls.to(device, non_blocking=True)\n",
    "        with torch.cuda.amp.autocast(enabled=device.type == \"cuda\"):\n",
    "            outputs = model(vids)\n",
    "        preds = outputs.argmax(dim=1) # Get predicted labels\n",
    "        correct += (preds == lbls).sum().item() # Count correct predictions\n",
    "        total   += lbls.size(0) # Count total predictions\n",
    "val_acc = correct / total if total else 0.0 # Calculate accuracy\n",
    "print(f\"Epoch {epoch+1:02d} | val acc : {val_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7127200,
     "sourceId": 11382528,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
