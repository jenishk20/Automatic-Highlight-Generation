{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65d1b62",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-14T16:16:43.820562Z",
     "iopub.status.busy": "2025-04-14T16:16:43.820304Z",
     "iopub.status.idle": "2025-04-14T23:10:56.884113Z",
     "shell.execute_reply": "2025-04-14T23:10:56.883295Z"
    },
    "papermill": {
     "duration": 24853.512134,
     "end_time": "2025-04-14T23:10:57.329020",
     "exception": false,
     "start_time": "2025-04-14T16:16:43.816886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
      "100%|██████████| 83.3M/83.3M [00:00<00:00, 187MB/s]\n",
      "/tmp/ipykernel_19/2040576709.py:195: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=device.type == \"cuda\")\n",
      "Epoch 1/20:   0%|          | 0/562 [00:00<?, ?it/s]/tmp/ipykernel_19/2040576709.py:207: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=device.type == \"cuda\"):\n",
      "Epoch 1/20: 100%|██████████| 562/562 [20:42<00:00,  2.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train loss: 2.4744\n",
      "✔ Saved checkpoint → checkpoints/checkpoint_epoch_01.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 562/562 [20:26<00:00,  2.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | train loss: 2.1943\n",
      "✔ Saved checkpoint → checkpoints/checkpoint_epoch_02.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 562/562 [20:33<00:00,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | train loss: 1.9119\n",
      "✔ Saved checkpoint → checkpoints/checkpoint_epoch_03.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 562/562 [20:26<00:00,  2.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | train loss: 1.7438\n",
      "✔ Saved checkpoint → checkpoints/checkpoint_epoch_04.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 562/562 [20:29<00:00,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | train loss: 1.5724\n",
      "✔ Saved checkpoint → checkpoints/checkpoint_epoch_05.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 562/562 [20:26<00:00,  2.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | train loss: 1.3705\n",
      "✔ Saved checkpoint → checkpoints/checkpoint_epoch_06.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 562/562 [20:12<00:00,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | train loss: 1.2788\n",
      "✔ Saved checkpoint → checkpoints/checkpoint_epoch_07.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 562/562 [20:20<00:00,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | train loss: 1.1250\n",
      "✔ Saved checkpoint → checkpoints/checkpoint_epoch_08.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 562/562 [20:35<00:00,  2.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | train loss: 1.0401\n",
      "✔ Saved checkpoint → checkpoints/checkpoint_epoch_09.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 562/562 [20:30<00:00,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | train loss: 0.9306\n",
      "✔ Saved checkpoint → checkpoints/checkpoint_epoch_10.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 562/562 [20:36<00:00,  2.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | train loss: 0.8243\n",
      "✔ Saved checkpoint → checkpoints/checkpoint_epoch_11.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 562/562 [20:36<00:00,  2.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | train loss: 0.7230\n",
      "✔ Saved checkpoint → checkpoints/checkpoint_epoch_12.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████| 562/562 [20:36<00:00,  2.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | train loss: 0.6800\n",
      "✔ Saved checkpoint → checkpoints/checkpoint_epoch_13.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████| 562/562 [20:15<00:00,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | train loss: 0.6103\n",
      "✔ Saved checkpoint → checkpoints/checkpoint_epoch_14.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████| 562/562 [20:17<00:00,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | train loss: 0.5787\n",
      "✔ Saved checkpoint → checkpoints/checkpoint_epoch_15.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████| 562/562 [20:15<00:00,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | train loss: 0.5053\n",
      "✔ Saved checkpoint → checkpoints/checkpoint_epoch_16.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|██████████| 562/562 [20:20<00:00,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | train loss: 0.3974\n",
      "✔ Saved checkpoint → checkpoints/checkpoint_epoch_17.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|██████████| 562/562 [20:23<00:00,  2.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | train loss: 0.3931\n",
      "✔ Saved checkpoint → checkpoints/checkpoint_epoch_18.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|██████████| 562/562 [20:13<00:00,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | train loss: 0.3557\n",
      "✔ Saved checkpoint → checkpoints/checkpoint_epoch_19.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████| 562/562 [20:21<00:00,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | train loss: 0.3234\n",
      "✔ Saved checkpoint → checkpoints/checkpoint_epoch_20.pth\n",
      "\n",
      "Training complete – final model saved as 'resnet_gru_highlight_model.pth'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/2040576709.py:257: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=device.type == \"cuda\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy : 0.5355\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "\n",
    "\n",
    "class ResNetFeatureExtractor(nn.Module):\n",
    "    \"\"\"ResNet‑34 up to global‑pooling. 512‑D output per frame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fine_tune : bool\n",
    "        If **False** (default) the backbone is frozen to save memory.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, fine_tune: bool = False):\n",
    "        super().__init__()\n",
    "        backbone = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)\n",
    "        self.backbone = nn.Sequential(*list(backbone.children())[:-1])  # strip FC\n",
    "        self.fine_tune = fine_tune\n",
    "        if not fine_tune:\n",
    "            for p in self.backbone.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "    def forward(self, x):  # (N, 3, 224, 224)\n",
    "        if self.fine_tune:\n",
    "            feats = self.backbone(x)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                feats = self.backbone(x)\n",
    "        return feats.view(x.size(0), -1)  # (N, 512)\n",
    "\n",
    "\n",
    "class GRUWithResNet(nn.Module):\n",
    "    \"\"\"Video classifier = frozen ResNet‑34 + temporal GRU + FC head.\"\"\"\n",
    "\n",
    "    def __init__(self, feature_size: int, hidden_size: int, output_size: int,\n",
    "                 num_layers: int = 2, dropout: float = 0.3, fine_tune_cnn: bool = False):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = ResNetFeatureExtractor(fine_tune=fine_tune_cnn)\n",
    "        self.gru = nn.GRU(feature_size,\n",
    "                          hidden_size,\n",
    "                          num_layers=num_layers,\n",
    "                          batch_first=True,\n",
    "                          dropout=dropout if num_layers > 1 else 0.0)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size * 2, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # (B, T, C, H, W)\n",
    "        b, t, c, h, w = x.size()\n",
    "        x = x.view(-1, c, h, w)                      # (B*T, C, H, W)\n",
    "        feats = self.feature_extractor(x)            # (B*T, 512)\n",
    "        feats = feats.view(b, t, -1)                 # (B, T, 512)\n",
    "        gru_out, _ = self.gru(feats)                 # (B, T, H)\n",
    "        logits = self.classifier(gru_out[:, -1, :])  # last step\n",
    "        return logits\n",
    "\n",
    "\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 video_paths: List[str],\n",
    "                 labels: List[str],\n",
    "                 label_to_index: dict,\n",
    "                 max_frames: int = 64,\n",
    "                 transform=None):\n",
    "        self.video_paths = video_paths\n",
    "        self.labels = labels\n",
    "        self.label_to_index = label_to_index\n",
    "        self.max_frames = max_frames\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_paths)\n",
    "\n",
    "    def _sample_frames(self, frames: List[np.ndarray]) -> List[np.ndarray]:\n",
    "        if len(frames) <= self.max_frames:\n",
    "            return frames\n",
    "        # uniform sampling\n",
    "        idxs = np.linspace(0, len(frames) - 1, self.max_frames, dtype=int)\n",
    "        return [frames[i] for i in idxs]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_path = self.video_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # --- decode video --- #\n",
    "        frames = []\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = cv2.resize(frame, (224, 224))\n",
    "            frame = frame[:, :, ::-1]  # BGR→RGB\n",
    "            frame = frame / 255.0\n",
    "            if self.transform:\n",
    "                frame = self.transform(frame)\n",
    "            frames.append(frame)\n",
    "        cap.release()\n",
    "\n",
    "        if not frames:\n",
    "            raise RuntimeError(f\"Could not read frames from {video_path}\")\n",
    "\n",
    "        frames = self._sample_frames(frames)\n",
    "        frames = np.stack(frames)                      # (T, H, W, C)\n",
    "        frames_tensor = torch.tensor(frames).permute(0, 3, 1, 2).float()\n",
    "        label_idx = self.label_to_index[label]\n",
    "        return frames_tensor, label_idx\n",
    "\n",
    "\n",
    "def load_data(root_directory):\n",
    "    video_paths, labels = [], []\n",
    "    for folder_name in os.listdir(root_directory):\n",
    "        folder_path = os.path.join(root_directory, folder_name)\n",
    "        if os.path.isdir(folder_path):\n",
    "            for fname in os.listdir(folder_path):\n",
    "                if fname.lower().endswith((\".mp4\", \".avi\", \".mov\")):\n",
    "                    video_paths.append(os.path.join(folder_path, fname))\n",
    "                    labels.append(folder_name)\n",
    "    return video_paths, labels\n",
    "\n",
    "\n",
    "\n",
    "root_directory = r\"/kaggle/input/highlight-label-extracted/extracted\"  \n",
    "video_paths, labels = load_data(root_directory)\n",
    "\n",
    "unique_labels = sorted(set(labels))\n",
    "label_to_index = {lbl: i for i, lbl in enumerate(unique_labels)}\n",
    "index_to_label = {i: lbl for lbl, i in label_to_index.items()}\n",
    "\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "    video_paths, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "\n",
    "\n",
    "feature_size = 512\n",
    "hidden_size = 512\n",
    "output_size = len(unique_labels)\n",
    "num_layers   = 2\n",
    "num_epochs   = 20\n",
    "batch_size   = 2  \n",
    "learning_rate = 1e-4\n",
    "checkpoint_dir = \"checkpoints\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = VideoDataset(train_paths, train_labels, label_to_index)\n",
    "val_dataset   = VideoDataset(val_paths,   val_labels,   label_to_index)\n",
    "train_loader  = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,  pin_memory=True)\n",
    "val_loader    = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "\n",
    "model = GRUWithResNet(feature_size, hidden_size, output_size, num_layers).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=device.type == \"cuda\")\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for vids, lbls in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        vids, lbls = vids.to(device, non_blocking=True), lbls.to(device, non_blocking=True)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(enabled=device.type == \"cuda\"):\n",
    "            outputs = model(vids)\n",
    "            loss = criterion(outputs, lbls)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1:02d} | train loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # -------------------- validation -------------------- #\n",
    "    # model.eval()\n",
    "    # correct = total = 0\n",
    "    # with torch.no_grad():\n",
    "    #     for vids, lbls in val_loader:\n",
    "    #         vids, lbls = vids.to(device, non_blocking=True), lbls.to(device, non_blocking=True)\n",
    "    #         with torch.cuda.amp.autocast(enabled=device.type == \"cuda\"):\n",
    "    #             outputs = model(vids)\n",
    "    #         preds = outputs.argmax(dim=1)\n",
    "    #         correct += (preds == lbls).sum().item()\n",
    "    #         total   += lbls.size(0)\n",
    "    # val_acc = correct / total if total else 0.0\n",
    "    # print(f\"Epoch {epoch+1:02d} | val acc : {val_acc:.4f}\")\n",
    "\n",
    "    # -------------------- checkpoint -------------------- #\n",
    "    ckpt_path = os.path.join(checkpoint_dir, f\"checkpoint_epoch_{epoch+1:02d}.pth\")\n",
    "    torch.save({\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"train_loss\": avg_loss,\n",
    "        # \"val_acc\": val_acc,\n",
    "        \"timestamp\": datetime.utcnow().isoformat()\n",
    "    }, ckpt_path)\n",
    "    print(f\"✔ Saved checkpoint → {ckpt_path}\\n\")\n",
    "\n",
    "final_model_path = \"resnet_gru_highlight_model.pth\"\n",
    "torch.save(model.state_dict(), final_model_path)\n",
    "print(f\"Training complete – final model saved as '{final_model_path}'.\")\n",
    "\n",
    "\n",
    "\n",
    "model.eval()\n",
    "correct = total = 0\n",
    "with torch.no_grad():\n",
    "    for vids, lbls in val_loader:\n",
    "        vids, lbls = vids.to(device, non_blocking=True), lbls.to(device, non_blocking=True)\n",
    "        with torch.cuda.amp.autocast(enabled=device.type == \"cuda\"):\n",
    "            outputs = model(vids)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == lbls).sum().item()\n",
    "        total   += lbls.size(0)\n",
    "val_acc = correct / total if total else 0.0\n",
    "print(f\"Validation accuracy : {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ab4ccc",
   "metadata": {
    "papermill": {
     "duration": 0.440234,
     "end_time": "2025-04-14T23:10:58.210412",
     "exception": false,
     "start_time": "2025-04-14T23:10:57.770178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7127522,
     "sourceId": 11383029,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 24861.616966,
   "end_time": "2025-04-14T23:11:01.339396",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-14T16:16:39.722430",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
