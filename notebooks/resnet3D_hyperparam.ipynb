{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision.models.video as video_models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'data_root': '9-classes',\n",
    "    'frame_height': 224,\n",
    "    'frame_width': 224,\n",
    "    'num_frames': 16,\n",
    "\n",
    "    'batch_size': 4,\n",
    "    'epochs': 3,\n",
    "    'learning_rate': 1e-3,\n",
    "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    'fold' : 2,\n",
    "    'optimizer': 'adam',\n",
    "    'scheduler': 'cosine',\n",
    "    'dropout': 0.3,\n",
    "\n",
    "    'model_type': 'r3d',\n",
    "    'pretrained': False,\n",
    "}\n",
    "\n",
    "# Set seed\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video to Label Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script to Load the Videos and map them to unique labels\n",
    "def load_video_paths(data_root):\n",
    "    video_paths = []\n",
    "    labels = []\n",
    "    class_names = sorted(os.listdir(data_root))\n",
    "    label_to_idx = {name: i for i, name in enumerate(class_names)}\n",
    "\n",
    "    for class_name in class_names:\n",
    "        class_dir = Path(data_root) / class_name\n",
    "        for video_file in class_dir.glob(\"*.mp4\"):\n",
    "            video_paths.append(str(video_file))\n",
    "            labels.append(label_to_idx[class_name])\n",
    "    return video_paths, labels, label_to_idx\n",
    "\n",
    "video_paths, labels, label_to_idx = load_video_paths(CONFIG['data_root'])\n",
    "idx_to_label = {v: k for k, v in label_to_idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader class to divide the clip into frames of particular size\n",
    "class SoccerDataset(Dataset):\n",
    "    def __init__(self, video_paths, labels, config):\n",
    "        self.video_paths = video_paths\n",
    "        self.labels = labels\n",
    "        self.config = config\n",
    "        self.transform = A.Compose([\n",
    "            A.Resize(height=config['frame_height'], width=config['frame_width']),\n",
    "            A.Normalize(mean=[0.43216, 0.394666, 0.37645], std=[0.22803, 0.22145, 0.216989])\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.video_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        frames = self._load_video(path)\n",
    "        return frames, label\n",
    "\n",
    "    def _load_video(self, path):\n",
    "        cap = cv2.VideoCapture(path)\n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        indices = np.linspace(0, frame_count - 1, self.config['num_frames'], dtype=int)\n",
    "        frames = []\n",
    "\n",
    "        for i in indices:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                continue\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = self.transform(image=frame)['image']\n",
    "            frames.append(frame)\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "        frames = np.array(frames)\n",
    "        frames = np.transpose(frames, (3, 0, 1, 2))\n",
    "        return torch.from_numpy(frames).float()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D ResNet Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Resnet3D model architecture for defining the hidden layers and output layers\n",
    "class R3DClassifier(nn.Module):\n",
    "    def __init__(self, num_classes, config):\n",
    "        super(R3DClassifier, self).__init__()\n",
    "\n",
    "        model_type = config['model_type'].lower()\n",
    "        pretrained = config['pretrained']\n",
    "        dropout = config['dropout']\n",
    "\n",
    "        if model_type == 'r3d':\n",
    "            self.model = video_models.r3d_18(pretrained=pretrained)\n",
    "        elif model_type == 'mc3':\n",
    "            self.model = video_models.mc3_18(pretrained=pretrained)\n",
    "        elif model_type == 'r2plus1d':\n",
    "            self.model = video_models.r2plus1d_18(pretrained=pretrained)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model_type '{model_type}' in CONFIG\")\n",
    "\n",
    "        in_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(in_features, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "k_folds = CONFIG['fold']\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "all_fold_accuracies = []\n",
    "fold_tracking = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(video_paths, labels)):\n",
    "    print(f\"\\n{'='*30}\\n▶️ Fold {fold+1}/{k_folds}\\n{'='*30}\")\n",
    "\n",
    "    train_paths_fold = [video_paths[i] for i in train_idx]\n",
    "    val_paths_fold = [video_paths[i] for i in val_idx]\n",
    "    train_labels_fold = [labels[i] for i in train_idx]\n",
    "    val_labels_fold = [labels[i] for i in val_idx]\n",
    "\n",
    "    train_loader = DataLoader(SoccerDataset(train_paths_fold, train_labels_fold, CONFIG), batch_size=CONFIG['batch_size'], shuffle=True)\n",
    "    val_loader = DataLoader(SoccerDataset(val_paths_fold, val_labels_fold, CONFIG), batch_size=CONFIG['batch_size'], shuffle=False)\n",
    "\n",
    "    model = R3DClassifier(num_classes=len(label_to_idx), config=CONFIG).to(CONFIG['device'])\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    if CONFIG['optimizer'] == 'adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=CONFIG['learning_rate'])\n",
    "    elif CONFIG['optimizer'] == 'sgd':\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=CONFIG['learning_rate'], momentum=0.9)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported optimizer in CONFIG.\")    \n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    epoch_train_accs, epoch_val_accs = [], []\n",
    "    epoch_train_errors, epoch_val_errors = [], []\n",
    "    for epoch in range(CONFIG['epochs']):\n",
    "        model.train()\n",
    "        train_preds, train_targets = [], []\n",
    "\n",
    "        for videos, labels_batch in tqdm(train_loader, desc=f\"Fold {fold+1} - Epoch {epoch+1}\"):\n",
    "            videos, labels_batch = videos.to(CONFIG['device']), labels_batch.to(CONFIG['device'])\n",
    "            outputs = model(videos)\n",
    "            loss = criterion(outputs, labels_batch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_preds.extend(torch.argmax(outputs, 1).cpu().numpy())\n",
    "            train_targets.extend(labels_batch.cpu().numpy())\n",
    "\n",
    "        train_acc = accuracy_score(train_targets, train_preds)\n",
    "        train_errors = sum(p != t for p, t in zip(train_preds, train_targets))\n",
    "\n",
    "        model.eval()\n",
    "        val_preds, val_targets = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for videos, labels_batch in val_loader:\n",
    "                videos, labels_batch = videos.to(CONFIG['device']), labels_batch.to(CONFIG['device'])\n",
    "                outputs = model(videos)\n",
    "                val_preds.extend(torch.argmax(outputs, 1).cpu().numpy())\n",
    "                val_targets.extend(labels_batch.cpu().numpy())\n",
    "\n",
    "        val_acc = accuracy_score(val_targets, val_preds)\n",
    "        val_errors = sum(p != t for p, t in zip(val_preds, val_targets))\n",
    "        print(f\"✅ Epoch {epoch+1}: Train Acc = {train_acc:.4f}, Val Acc = {val_acc:.4f}\")\n",
    "        \n",
    "        epoch_train_accs.append(train_acc)\n",
    "        epoch_val_accs.append(val_acc)\n",
    "        epoch_train_errors.append(train_errors)\n",
    "        epoch_val_errors.append(val_errors)\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            model_path = f\"models/best_model_fold{fold+1}.pth\"\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(f\"💾 Saved best model for Fold {fold+1}: {model_path}\")\n",
    "    \n",
    "    fold_tracking.append({\n",
    "    'fold': fold + 1,\n",
    "    'train_accuracies': epoch_train_accs,\n",
    "    'val_accuracies': epoch_val_accs,\n",
    "    'train_errors': epoch_train_errors,\n",
    "    'val_errors': epoch_val_errors,\n",
    "    'best_val_acc': best_val_acc\n",
    "    })\n",
    "\n",
    "    all_fold_accuracies.append(best_val_acc)\n",
    "    \n",
    "\n",
    "run_summary = {\n",
    "    'config': {\n",
    "        'learning_rate': float(CONFIG['learning_rate']),\n",
    "        'batch_size': int(CONFIG['batch_size']),\n",
    "        'dropout': float(CONFIG['dropout']),\n",
    "        'num_frames': int(CONFIG['num_frames']),\n",
    "        'optimizer': CONFIG['optimizer'],\n",
    "        'k_folds': int(CONFIG['fold'])\n",
    "    },\n",
    "    'fold_accuracies': [float(a) for a in all_fold_accuracies],\n",
    "    'avg_accuracy': float(np.mean(all_fold_accuracies)),\n",
    "    'fold_tracking': fold_tracking  # we’ll sanitize this below\n",
    "}\n",
    "\n",
    "\n",
    "def sanitize(obj):\n",
    "    if isinstance(obj, (np.int64, np.int32, np.integer)):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, (np.float64, np.float32, np.floating)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, list):\n",
    "        return [sanitize(x) for x in obj]\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: sanitize(v) for k, v in obj.items()}\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "run_summary['fold_tracking'] = sanitize(fold_tracking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dumping the fold and training results to the json file\n",
    "with open(f\"run_result_lr{CONFIG['learning_rate']}.json\", \"w\") as f:\n",
    "    json.dump(run_summary, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the JSON file to view results\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open(f\"run_result_lr{CONFIG['learning_rate']}.json\") as f:\n",
    "    results = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results\n",
    "for fold in results['fold_tracking']:\n",
    "    f = fold['fold']\n",
    "    epochs = list(range(1, len(fold['train_accuracies']) + 1))\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Accuracy Plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, fold['train_accuracies'], label='Train Acc')\n",
    "    plt.plot(epochs, fold['val_accuracies'], label='Val Acc')\n",
    "    plt.title(f\"Fold {f} - Accuracy\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Error Plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, fold['train_errors'], label='Train Errors')\n",
    "    plt.plot(epochs, fold['val_errors'], label='Val Errors')\n",
    "    plt.title(f\"Fold {f} - Errors\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"# Errors\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in results['fold_tracking']:\n",
    "    print(f\"Fold {fold['fold']} | Best Val Accuracy: {fold['best_val_acc']:.4f} | Final Train Accuracy: {fold['train_accuracies'][-1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use val_paths_fold and val_labels_fold from last fold\n",
    "val_dataset = SoccerDataset(val_paths_fold, val_labels_fold, CONFIG)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "all_preds, all_true, all_probs, all_videos = [], [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (videos, labels_batch) in enumerate(tqdm(val_loader, desc=\"Evaluating error analysis\")):\n",
    "        videos = videos.to(CONFIG['device'])\n",
    "        outputs = model(videos)\n",
    "        probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        preds = torch.argmax(probs, dim=1).cpu().numpy()\n",
    "\n",
    "        all_preds.extend(preds)\n",
    "        all_true.extend(labels_batch.numpy())\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "        all_videos.extend(val_paths_fold[i*CONFIG['batch_size']: (i+1)*CONFIG['batch_size']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"video_path\": all_videos,\n",
    "    \"true_label\": [idx_to_label[i] for i in all_true],\n",
    "    \"predicted_label\": [idx_to_label[i] for i in all_preds],\n",
    "    \"correct\": np.array(all_true) == np.array(all_preds),\n",
    "    \"confidence\": [row[p] for row, p in zip(all_probs, all_preds)]\n",
    "})\n",
    "\n",
    "# Save CSV\n",
    "df.to_csv(\"fold_predictions.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total errors\n",
    "total = len(df)\n",
    "errors = df[~df['correct']]\n",
    "print(f\"\\nTotal errors: {len(errors)} out of {total} ({100*len(errors)/total:.2f}%)\")\n",
    "\n",
    "# Most common misclassifications\n",
    "misclass_df = errors.groupby(['true_label', 'predicted_label']).size().reset_index(name='Count')\n",
    "misclass_df = misclass_df.sort_values('Count', ascending=False)\n",
    "print(\"\\nMost common misclassifications:\")\n",
    "print(misclass_df.head(10))\n",
    "\n",
    "# Error rate by class\n",
    "class_errors = df.groupby('true_label')['correct'].agg(['count', lambda x: (~x).sum()])\n",
    "class_errors.columns = ['Total', 'Errors']\n",
    "class_errors['Error Rate'] = class_errors['Errors'] / class_errors['Total']\n",
    "class_errors = class_errors.sort_values('Error Rate', ascending=False)\n",
    "print(\"\\nError rates by class:\")\n",
    "print(class_errors)\n",
    "\n",
    "# Highest confidence incorrect predictions\n",
    "print(\"\\nHighest confidence errors:\")\n",
    "print(errors.sort_values('confidence', ascending=False).head(10)[['video_path', 'true_label', 'predicted_label', 'confidence']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error rate bar plot\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.barplot(x=class_errors.index, y=class_errors['Error Rate'])\n",
    "plt.title(\"Class-wise Error Rate\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(df['true_label'], df['predicted_label'], labels=list(label_to_idx.keys()))\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_to_idx.keys(), yticklabels=label_to_idx.keys())\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
